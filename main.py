"""
æ—¶é—´åºåˆ—å› æœæ¨æ–­é…ç½®å’Œè¿è¡Œè„šæœ¬
æä¾›ç®€å•çš„æ¥å£æ¥é…ç½®å’Œè¿è¡Œå› æœæ¨æ–­åˆ†æ
"""

import os
import yaml
import argparse
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
import pandas as pd
import numpy as np

@dataclass
class CausalInferenceConfig:
    """å› æœæ¨æ–­é…ç½®ç±»"""
    
    # æ•°æ®ç”Ÿæˆé…ç½®
    n_days: int = 180
    intervention_probability: float = 0.25
    base_intervention_effect: float = 4.0
    effect_decay: float = 0.7
    seasonal_components: List[int] = None
    noise_level: float = 1.0
    
    # åˆ†æé…ç½®
    intervention_col: str = 'treatment'
    target_col: str = 'target'
    covariates: List[str] = None
    
    # æ—¶å˜åˆ†æé…ç½®
    start_idx: Optional[int] = None
    end_idx: Optional[int] = None
    step_size: int = 1
    min_context: int = 30
    context_window: Optional[int] = None
    
    # æ¨¡å‹é…ç½®
    use_real_models: bool = True
    
    # è¾“å‡ºé…ç½®
    save_results: bool = True
    output_dir: str = "causal_analysis_results"
    plot_results: bool = True
    verbose: bool = True
    
    def __post_init__(self):
        if self.seasonal_components is None:
            self.seasonal_components = [7, 30, 90]
        if self.covariates is None:
            self.covariates = ['is_weekend', 'is_month_start']

class CausalAnalysisRunner:
    """å› æœåˆ†æè¿è¡Œå™¨"""
    
    def __init__(self, config: CausalInferenceConfig):
        self.config = config
        self.system = None
        self.data = None
        self.results = None
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if config.save_results:
            os.makedirs(config.output_dir, exist_ok=True)
    
    def load_custom_data(self, data_path: str, 
                        timestamp_col: str = 'timestamp',
                        target_col: str = 'target',
                        intervention_col: str = 'treatment') -> pd.DataFrame:
        """åŠ è½½è‡ªå®šä¹‰æ•°æ®"""
        
        print(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½æ–¹æ³•
        if data_path.endswith('.csv'):
            data = pd.read_csv(data_path)
        elif data_path.endswith('.parquet'):
            data = pd.read_parquet(data_path)
        elif data_path.endswith('.json'):
            data = pd.read_json(data_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {data_path}")
        
        # éªŒè¯å¿…è¦åˆ—å­˜åœ¨
        required_cols = [timestamp_col, target_col, intervention_col]
        missing_cols = [col for col in required_cols if col not in data.columns]
        
        if missing_cols:
            raise ValueError(f"æ•°æ®ä¸­ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ ‡å‡†åŒ–åˆ—å
        data = data.rename(columns={
            timestamp_col: 'timestamp',
            target_col: 'target',
            intervention_col: 'treatment'
        })
        
        # ç¡®ä¿æ—¶é—´æˆ³æ ¼å¼æ­£ç¡®
        data['timestamp'] = pd.to_datetime(data['timestamp'])
        
        # ç¡®ä¿å¹²é¢„åˆ—æ˜¯äºŒå…ƒçš„
        data['treatment'] = data['treatment'].astype(int)
        
        print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ: {data.shape}")
        print(f"   æ—¶é—´èŒƒå›´: {data['timestamp'].min()} åˆ° {data['timestamp'].max()}")
        print(f"   å¹²é¢„æ¬¡æ•°: {data['treatment'].sum()}")
        
        return data
    
    def generate_synthetic_data(self) -> pd.DataFrame:
        """ç”Ÿæˆåˆæˆæ•°æ®"""
        
        print("ğŸ² ç”Ÿæˆåˆæˆæ—¶é—´åºåˆ—æ•°æ®...")
        
        # å¯¼å…¥ç³»ç»Ÿï¼ˆè¿™é‡Œéœ€è¦å‰é¢å®šä¹‰çš„ç±»ï¼‰
        from real_ts_causal_inference import RealTimeSeriesCausalInference
        
        if self.system is None:
            self.system = RealTimeSeriesCausalInference(
                use_real_models=self.config.use_real_models
            )
        
        data = self.system.generate_realistic_timeseries(
            n_days=self.config.n_days,
            intervention_probability=self.config.intervention_probability,
            base_intervention_effect=self.config.base_intervention_effect,
            effect_decay=self.config.effect_decay,
            seasonal_components=self.config.seasonal_components,
            noise_level=self.config.noise_level
        )
        
        print(f"   âœ… åˆæˆæ•°æ®ç”Ÿæˆå®Œæˆ: {data.shape}")
        
        return data
    
    def run_analysis(self, data: pd.DataFrame = None) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å› æœåˆ†æ"""
        
        print("\nğŸš€ å¼€å§‹å› æœæ¨æ–­åˆ†æ")
        print("="*60)
        
        # 1. å‡†å¤‡æ•°æ®
        if data is None:
            data = self.generate_synthetic_data()
        
        self.data = data
        
        # 2. åˆå§‹åŒ–ç³»ç»Ÿ
        if self.system is None:
            from real_ts_causal_inference import RealTimeSeriesCausalInference
            self.system = RealTimeSeriesCausalInference(
                use_real_models=self.config.use_real_models
            )
        
        # 3. è®¾ç½®åˆ†æå‚æ•°
        start_idx = self.config.start_idx or self.config.min_context
        end_idx = self.config.end_idx or len(data) - 1
        
        print(f"ğŸ“Š åˆ†æé…ç½®:")
        print(f"   æ—¶é—´èŒƒå›´: {start_idx} åˆ° {end_idx}")
        print(f"   æ­¥é•¿: {self.config.step_size}")
        print(f"   æœ€å°ä¸Šä¸‹æ–‡: {self.config.min_context}")
        print(f"   ä½¿ç”¨çœŸå®æ¨¡å‹: {self.config.use_real_models}")
        
        # 4. è¿è¡Œæ—¶å˜å› æœåˆ†æ
        try:
            results = self.system.run_time_varying_causal_analysis(
                data,
                intervention_col=self.config.intervention_col,
                target_col=self.config.target_col,
                start_idx=start_idx,
                end_idx=end_idx,
                step_size=self.config.step_size,
                min_context=self.config.min_context
            )
            
            self.results = results
            
            print(f"\nâœ… å› æœåˆ†æå®Œæˆ!")
            print(f"   æˆåŠŸåˆ†æ {len(results)} ä¸ªæ—¶é—´ç‚¹")
            
        except Exception as e:
            print(f"\nâŒ å› æœåˆ†æå¤±è´¥: {e}")
            raise
        
        # 5. ä¿å­˜ç»“æœ
        if self.config.save_results:
            self._save_results()
        
        # 6. ç”Ÿæˆå¯è§†åŒ–
        if self.config.plot_results:
            self._generate_plots()
        
        return {
            'data': self.data,
            'results': self.results,
            'config': self.config,
            'system': self.system
        }
    
    def _save_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        
        print(f"\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {self.config.output_dir}")
        
        # ä¿å­˜åŸå§‹æ•°æ®
        self.data.to_csv(
            os.path.join(self.config.output_dir, 'original_data.csv'), 
            index=False
        )
        
        # ä¿å­˜å› æœåˆ†æç»“æœ
        self.results.to_csv(
            os.path.join(self.config.output_dir, 'causal_results.csv'), 
            index=False
        )
        
        # ä¿å­˜é…ç½®
        config_dict = asdict(self.config)
        with open(os.path.join(self.config.output_dir, 'config.yaml'), 'w') as f:
            yaml.dump(config_dict, f, default_flow_style=False)
        
        # ä¿å­˜æ±‡æ€»ç»Ÿè®¡
        summary = self._generate_summary_stats()
        with open(os.path.join(self.config.output_dir, 'summary.txt'), 'w') as f:
            f.write(summary)
        
        print("   âœ… ç»“æœä¿å­˜å®Œæˆ")
    
    def _generate_plots(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        
        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # ç”Ÿæˆä¸»è¦åˆ†æå›¾è¡¨
        self.system.plot_comprehensive_analysis(
            self.data, self.results,
            intervention_col=self.config.intervention_col,
            target_col=self.config.target_col
        )
        
        # å¦‚æœéœ€è¦ä¿å­˜å›¾è¡¨
        if self.config.save_results:
            import matplotlib.pyplot as plt
            plt.savefig(
                os.path.join(self.config.output_dir, 'causal_analysis_plots.png'),
                dpi=300, bbox_inches='tight'
            )
            print(f"   ğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ°: {self.config.output_dir}/causal_analysis_plots.png")
    
    def _generate_summary_stats(self) -> str:
        """ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡ä¿¡æ¯"""
        
        summary_lines = [
            "æ—¶é—´åºåˆ—å› æœæ¨æ–­åˆ†ææŠ¥å‘Š",
            "=" * 50,
            "",
            f"åˆ†ææ—¥æœŸ: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"æ•°æ®æ—¶é—´èŒƒå›´: {self.data['timestamp'].min()} åˆ° {self.data['timestamp'].max()}",
            f"æ€»æ—¶é—´ç‚¹æ•°: {len(self.data)}",
            f"åˆ†ææ—¶é—´ç‚¹æ•°: {len(self.results)}",
            "",
            "å¹²é¢„ç»Ÿè®¡:",
            f"  æ€»å¹²é¢„æ¬¡æ•°: {self.data[self.config.intervention_col].sum()}",
            f"  å¹²é¢„ç‡: {self.data[self.config.intervention_col].mean():.3f}",
            "",
            "å› æœæ•ˆåº”ä¼°è®¡:",
            f"  å¹³å‡ATE: {self.results['ate'].mean():.4f}",
            f"  ATEæ ‡å‡†å·®: {self.results['ate'].std():.4f}",
            f"  ATEèŒƒå›´: [{self.results['ate'].min():.4f}, {self.results['ate'].max():.4f}]",
            f"  å¹³å‡ä¸ç¡®å®šæ€§: {self.results['uncertainty'].mean():.4f}",
            "",
            "æ˜¾è‘—æ€§åˆ†æ:",
            f"  æ˜¾è‘—æ­£æ•ˆåº”: {(self.results['ate'] > self.results['uncertainty']).sum()} ä¸ªæ—¶é—´ç‚¹",
            f"  æ˜¾è‘—è´Ÿæ•ˆåº”: {(self.results['ate'] < -self.results['uncertainty']).sum()} ä¸ªæ—¶é—´ç‚¹",
            ""
        ]
        
        # å¦‚æœæœ‰çœŸå®æ•ˆåº”ï¼Œæ·»åŠ ç²¾åº¦è¯„ä¼°
        if 'true_effect' in self.results.columns:
            true_effects = []
            for idx in self.results['query_idx']:
                if idx > 0:
                    current_true = self.data.iloc[idx]['true_intervention_effect']
                    prev_true = self.data.iloc[idx-1]['true_intervention_effect']
                    true_effects.append(current_true - prev_true)
                else:
                    true_effects.append(self.data.iloc[idx]['true_intervention_effect'])
            
            estimation_error = self.results['ate'] - true_effects
            rmse = np.sqrt(np.mean(estimation_error**2))
            mae = np.mean(np.abs(estimation_error))
            correlation = np.corrcoef(self.results['ate'], true_effects)[0, 1]
            
            summary_lines.extend([
                "ä¼°è®¡ç²¾åº¦è¯„ä¼°:",
                f"  RMSE: {rmse:.4f}",
                f"  MAE: {mae:.4f}",
                f"  ç›¸å…³ç³»æ•°: {correlation:.4f}",
                ""
            ])
        
        summary_lines.extend([
            "é…ç½®å‚æ•°:",
            f"  ä½¿ç”¨çœŸå®æ¨¡å‹: {self.config.use_real_models}",
            f"  æœ€å°ä¸Šä¸‹æ–‡é•¿åº¦: {self.config.min_context}",
            f"  åˆ†ææ­¥é•¿: {self.config.step_size}",
        ])
        
        return "\n".join(summary_lines)

def load_config_from_file(config_path: str) -> CausalInferenceConfig:
    """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®"""
    
    with open(config_path, 'r') as f:
        config_dict = yaml.safe_load(f)
    
    return CausalInferenceConfig(**config_dict)

def create_example_config() -> CausalInferenceConfig:
    """åˆ›å»ºç¤ºä¾‹é…ç½®"""
    
    return CausalInferenceConfig(
        # æ•°æ®é…ç½®
        n_days=200,
        intervention_probability=0.3,
        base_intervention_effect=5.0,
        effect_decay=0.8,
        seasonal_components=[7, 30, 90],
        noise_level=1.2,
        
        # åˆ†æé…ç½®
        intervention_col='treatment',
        target_col='target',
        covariates=['is_weekend', 'is_month_start'],
        
        # æ—¶å˜åˆ†æé…ç½®
        start_idx=50,
        end_idx=180,
        step_size=2,
        min_context=40,
        
        # æ¨¡å‹é…ç½®
        use_real_models=True,
        
        # è¾“å‡ºé…ç½®
        save_results=True,
        output_dir="example_causal_analysis",
        plot_results=True,
        verbose=True
    )

def run_quick_analysis(n_days: int = 150,
                      intervention_prob: float = 0.25,
                      intervention_effect: float = 4.0,
                      use_real_models: bool = True) -> Dict[str, Any]:
    """å¿«é€Ÿè¿è¡Œå› æœåˆ†æ"""
    
    config = CausalInferenceConfig(
        n_days=n_days,
        intervention_probability=intervention_prob,
        base_intervention_effect=intervention_effect,
        use_real_models=use_real_models,
        output_dir=f"quick_analysis_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}"
    )
    
    runner = CausalAnalysisRunner(config)
    return runner.run_analysis()

def run_from_custom_data(data_path: str,
                        timestamp_col: str = 'timestamp',
                        target_col: str = 'target', 
                        intervention_col: str = 'treatment',
                        **kwargs) -> Dict[str, Any]:
    """ä»è‡ªå®šä¹‰æ•°æ®è¿è¡Œå› æœåˆ†æ"""
    
    config = CausalInferenceConfig(
        target_col=target_col,
        intervention_col=intervention_col,
        output_dir=f"custom_analysis_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}",
        **kwargs
    )
    
    runner = CausalAnalysisRunner(config)
    data = runner.load_custom_data(data_path, timestamp_col, target_col, intervention_col)
    
    return runner.run_analysis(data)

def main():
    """å‘½ä»¤è¡Œä¸»å‡½æ•°"""
    
    parser = argparse.ArgumentParser(description='æ—¶é—´åºåˆ—å› æœæ¨æ–­åˆ†æå·¥å…·')
    
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„ (YAMLæ ¼å¼)')
    parser.add_argument('--data', type=str, help='è‡ªå®šä¹‰æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿåˆ†ææ¨¡å¼')
    parser.add_argument('--n-days', type=int, default=150, help='ç”Ÿæˆæ•°æ®çš„å¤©æ•°')
    parser.add_argument('--intervention-prob', type=float, default=0.25, help='å¹²é¢„æ¦‚ç‡')
    parser.add_argument('--intervention-effect', type=float, default=4.0, help='å¹²é¢„æ•ˆåº”å¤§å°')
    parser.add_argument('--no-real-models', action='store_true', help='ä¸ä½¿ç”¨çœŸå®æ¨¡å‹')
    parser.add_argument('--output-dir', type=str, help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    if args.quick:
        # å¿«é€Ÿåˆ†ææ¨¡å¼
        print("ğŸš€ å¯åŠ¨å¿«é€Ÿå› æœåˆ†æ...")
        results = run_quick_analysis(
            n_days=args.n_days,
            intervention_prob=args.intervention_prob,
            intervention_effect=args.intervention_effect,
            use_real_models=not args.no_real_models
        )
        print("âœ… å¿«é€Ÿåˆ†æå®Œæˆ!")
        
    elif args.data:
        # è‡ªå®šä¹‰æ•°æ®åˆ†æ
        print(f"ğŸ“Š ä»è‡ªå®šä¹‰æ•°æ®è¿è¡Œåˆ†æ: {args.data}")
        
        kwargs = {}
        if args.output_dir:
            kwargs['output_dir'] = args.output_dir
        if args.no_real_models:
            kwargs['use_real_models'] = False
            
        results = run_from_custom_data(args.data, **kwargs)
        print("âœ… è‡ªå®šä¹‰æ•°æ®åˆ†æå®Œæˆ!")
        
    elif args.config:
        # é…ç½®æ–‡ä»¶æ¨¡å¼
        print(f"âš™ï¸ ä»é…ç½®æ–‡ä»¶è¿è¡Œ: {args.config}")
        config = load_config_from_file(args.config)
        
        if args.output_dir:
            config.output_dir = args.output_dir
        if args.no_real_models:
            config.use_real_models = False
            
        runner = CausalAnalysisRunner(config)
        results = runner.run_analysis()
        print("âœ… é…ç½®æ–‡ä»¶åˆ†æå®Œæˆ!")
        
    else:
        # é»˜è®¤ç¤ºä¾‹åˆ†æ
        print("ğŸ“‹ è¿è¡Œç¤ºä¾‹åˆ†æ...")
        config = create_example_config()
        
        if args.output_dir:
            config.output_dir = args.output_dir
        if args.no_real_models:
            config.use_real_models = False
            
        runner = CausalAnalysisRunner(config)
        results = runner.run_analysis()
        print("âœ… ç¤ºä¾‹åˆ†æå®Œæˆ!")
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    
    print("=" * 80)
    print("ğŸ”¬ æ—¶é—´åºåˆ—å› æœæ¨æ–­åˆ†æå·¥å…·")
    print("=" * 80)
    
    # ç¤ºä¾‹1: å¿«é€Ÿåˆ†æ
    print("\nğŸ“Š ç¤ºä¾‹1: å¿«é€Ÿå› æœåˆ†æ")
    quick_results = run_quick_analysis(
        n_days=100,
        intervention_prob=0.3,
        intervention_effect=5.0,
        use_real_models=True
    )
    
    # ç¤ºä¾‹2: è¯¦ç»†é…ç½®åˆ†æ
    print("\nğŸ“Š ç¤ºä¾‹2: è¯¦ç»†é…ç½®åˆ†æ")
    detailed_config = CausalInferenceConfig(
        n_days=150,
        intervention_probability=0.25,
        base_intervention_effect=4.0,
        effect_decay=0.7,
        seasonal_components=[7, 30],
        noise_level=1.0,
        start_idx=30,
        step_size=3,
        min_context=25,
        output_dir="detailed_analysis_example",
        verbose=True
    )
    
    detailed_runner = CausalAnalysisRunner(detailed_config)
    detailed_results = detailed_runner.run_analysis()
    
    print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹åˆ†æå®Œæˆ!")
    print("ğŸ“ æŸ¥çœ‹è¾“å‡ºç›®å½•è·å–è¯¦ç»†ç»“æœ")